{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca5323ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0764d22",
   "metadata": {},
   "source": [
    "# getting the data\n",
    "\n",
    "We will use UCI label dataset\n",
    "\n",
    "Dataset is available here: https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f478955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2748 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Sentiment  Source\n",
       "0     So there is no way for me to plug it in here i...          0  amazon\n",
       "1                           Good case, Excellent value.          1  amazon\n",
       "2                                Great for the jawbone.          1  amazon\n",
       "3     Tied to charger for conversations lasting more...          0  amazon\n",
       "4                                     The mic is great.          1  amazon\n",
       "...                                                 ...        ...     ...\n",
       "2743  I think food should have flavor and texture an...          0    yelp\n",
       "2744                           Appetite instantly gone.          0    yelp\n",
       "2745  Overall I was not impressed and would not go b...          0    yelp\n",
       "2746  The whole experience was underwhelming, and I ...          0    yelp\n",
       "2747  Then, as if I hadn't wasted enough of my life ...          0    yelp\n",
       "\n",
       "[2748 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00331/sentiment%20labelled%20sentences.zip'\n",
    "response = urlopen(url)\n",
    "zipfile = ZipFile(BytesIO(response.read()))\n",
    "file_names = zipfile.namelist()\n",
    "# file_names\n",
    "\n",
    "# files to read\n",
    "files_to_read = []\n",
    "for s in file_names:\n",
    "    if '.txt' in s: \n",
    "        if '__MACOSX' not in s: \n",
    "            if 'readme.txt' not in s:\n",
    "                files_to_read.append(s)\n",
    "files_to_read\n",
    "    \n",
    "\n",
    "source_lists = ['amazon', 'imdb', 'yelp']\n",
    "\n",
    "for i in range(len(files_to_read)):\n",
    "    exec(f'df_{i} = pd.read_csv(zipfile.open(files_to_read[{i}]), delimiter=\"\\t\", names=[\"Text\",\"Sentiment\"])')\n",
    "    for j in range(len(source_lists)):\n",
    "        if source_lists[j] in files_to_read[i]:\n",
    "            exec(f'df_{i}[\"Source\"] = source_lists[{i}]')  \n",
    "\n",
    "\n",
    "# merging all the datasets from amazon, imdb, yelp\n",
    "df_all = pd.concat([df_0, df_1, df_2])\n",
    "# reseting the index numbers\n",
    "df_all.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e984cc69",
   "metadata": {},
   "source": [
    "# nltk and spacy for nlp\n",
    "\n",
    "We will use nltk and spacy libraries in this notebook\n",
    "\n",
    "If you don't have nltk and spacy already installed please install them first.\n",
    "\n",
    "\n",
    "For spacy\n",
    "\n",
    "pip install -U spacy\n",
    "\n",
    "python -m spacy download en\n",
    "\n",
    "https://spacy.io/usage/linguistic-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c1f6184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adf26385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downloading the packages\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c17dd7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy\n",
    "# First you need to load the library\n",
    "nlp_spacy = spacy.load('en_core_web_sm')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12ab61d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Apple PROPN NNP nsubj Xxxxx True False\n",
      "is be AUX VBZ aux xx True True\n",
      "looking look VERB VBG ROOT xxxx True False\n",
      "at at ADP IN prep xx True True\n",
      "buying buy VERB VBG pcomp xxxx True False\n",
      "U.K. U.K. PROPN NNP compound X.X. False False\n",
      "startup startup NOUN NN dobj xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "$ $ SYM $ quantmod $ False False\n",
      "1 1 NUM CD compound d False False\n",
      "billion billion NUM CD pobj xxxx True False\n",
      "\n",
      "\n",
      "Named Entities \n",
      "\n",
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "$1 billion 44 54 MONEY\n"
     ]
    }
   ],
   "source": [
    "# some attributes for spacy library\n",
    "text = \"Apple is looking at buying U.K. startup for $1 billion\"\n",
    "doc = nlp_spacy(text)\n",
    "\n",
    "for token in doc:\n",
    "        print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)\n",
    "\n",
    "print(\"\\n\\nNamed Entities \\n\")\n",
    "\n",
    "for token in doc.ents:\n",
    "        print(token.text, token.start_char, token.end_char, token.label_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef51b76d",
   "metadata": {},
   "source": [
    "Stemming a document\n",
    "You can write your own function that can stem documents. Here is one way to stem a document using Python filing:\n",
    "\n",
    "Take a document as the input.\n",
    "1. Read the document line by line\n",
    "2. Tokenize the line\n",
    "3. Stem the words\n",
    "4. Output the stemmed words (print on screen or write to a file)\n",
    "5. Repeat step 2 to step 5 until it is to the end of the document.\n",
    "\n",
    "source: https://www.datacamp.com/community/tutorials/stemming-lemmatization-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3880e9bd",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea235bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# This is nltk stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f99758c",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "\n",
    "Please see further about Porter Stemming here (https://tartarus.org/martin/PorterStemmer/)\n",
    "\n",
    "for NLTK\n",
    "Stemmers example (https://www.nltk.org/howto/stem.html)\n",
    "\n",
    "Stemmer is not available on Spacy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b346c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk\n",
    "nltk_porter_stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb374aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stop_words = stopwords.words('english')\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# creating a function for stemming\n",
    "def nltk_stemming(text):\n",
    "    # First tokenize the word. \n",
    "    # token_words = text.split()\n",
    "    \n",
    "    # simple method is to tonkenize the text\n",
    "    # token_words = word_tokenize(text)\n",
    "\n",
    "    # another method is to tokenize and remove punctuation\n",
    "    token_words = tokenizer.tokenize(text)\n",
    "\n",
    "    # Creating an empty list for text after porter stemmer\n",
    "    stem_sentence = []\n",
    "\n",
    "    # Iterating each word using Porter stemmer\n",
    "    for word in token_words:\n",
    "        # removing stopwords\n",
    "        if word in nltk_stop_words:\n",
    "            continue\n",
    "        else:\n",
    "            # Removing punctuation (, and -)\n",
    "            # word = re.sub(r\"[,-]\",'',word)\n",
    "            stem_sentence.append(nltk_porter_stem.stem(word))\n",
    "    # Join the word\n",
    "    return \" \".join(stem_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9c708a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Source</th>\n",
       "      <th>Text_nltk_stemming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "      <td>so way plug us unless i go convert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon</td>\n",
       "      <td>good case excel valu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon</td>\n",
       "      <td>great jawbon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "      <td>tie charger convers last 45 minut major problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon</td>\n",
       "      <td>the mic great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "      <td>i think food flavor textur lack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "      <td>appetit instantli gone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "      <td>overal i impress would go back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "      <td>the whole experi underwhelm i think go ninja s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "      <td>then i wast enough life pour salt wound draw t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2748 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Sentiment  Source  \\\n",
       "0     So there is no way for me to plug it in here i...          0  amazon   \n",
       "1                           Good case, Excellent value.          1  amazon   \n",
       "2                                Great for the jawbone.          1  amazon   \n",
       "3     Tied to charger for conversations lasting more...          0  amazon   \n",
       "4                                     The mic is great.          1  amazon   \n",
       "...                                                 ...        ...     ...   \n",
       "2743  I think food should have flavor and texture an...          0    yelp   \n",
       "2744                           Appetite instantly gone.          0    yelp   \n",
       "2745  Overall I was not impressed and would not go b...          0    yelp   \n",
       "2746  The whole experience was underwhelming, and I ...          0    yelp   \n",
       "2747  Then, as if I hadn't wasted enough of my life ...          0    yelp   \n",
       "\n",
       "                                     Text_nltk_stemming  \n",
       "0                    so way plug us unless i go convert  \n",
       "1                                  good case excel valu  \n",
       "2                                          great jawbon  \n",
       "3       tie charger convers last 45 minut major problem  \n",
       "4                                         the mic great  \n",
       "...                                                 ...  \n",
       "2743                    i think food flavor textur lack  \n",
       "2744                             appetit instantli gone  \n",
       "2745                     overal i impress would go back  \n",
       "2746  the whole experi underwhelm i think go ninja s...  \n",
       "2747  then i wast enough life pour salt wound draw t...  \n",
       "\n",
       "[2748 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['Text_nltk_stemming'] = df_all['Text'].apply(nltk_stemming)\n",
    "\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca24657d",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60045fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Source</th>\n",
       "      <th>Text_nltk_stemming</th>\n",
       "      <th>Text_spacy_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "      <td>so way plug us unless i go convert</td>\n",
       "      <td>way plug converter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon</td>\n",
       "      <td>good case excel valu</td>\n",
       "      <td>good case excellent value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon</td>\n",
       "      <td>great jawbon</td>\n",
       "      <td>great jawbone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "      <td>tie charger convers last 45 minut major problem</td>\n",
       "      <td>tie charger conversation last minute major pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon</td>\n",
       "      <td>the mic great</td>\n",
       "      <td>mic great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "      <td>i think food flavor textur lack</td>\n",
       "      <td>think food flavor texture lack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "      <td>appetit instantli gone</td>\n",
       "      <td>appetite instantly go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "      <td>overal i impress would go back</td>\n",
       "      <td>overall impressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "      <td>the whole experi underwhelm i think go ninja s...</td>\n",
       "      <td>experience underwhelming think ninja sushi time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "      <td>then i wast enough life pour salt wound draw t...</td>\n",
       "      <td>waste life pour salt wound draw time take brin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2748 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Sentiment  Source  \\\n",
       "0     So there is no way for me to plug it in here i...          0  amazon   \n",
       "1                           Good case, Excellent value.          1  amazon   \n",
       "2                                Great for the jawbone.          1  amazon   \n",
       "3     Tied to charger for conversations lasting more...          0  amazon   \n",
       "4                                     The mic is great.          1  amazon   \n",
       "...                                                 ...        ...     ...   \n",
       "2743  I think food should have flavor and texture an...          0    yelp   \n",
       "2744                           Appetite instantly gone.          0    yelp   \n",
       "2745  Overall I was not impressed and would not go b...          0    yelp   \n",
       "2746  The whole experience was underwhelming, and I ...          0    yelp   \n",
       "2747  Then, as if I hadn't wasted enough of my life ...          0    yelp   \n",
       "\n",
       "                                     Text_nltk_stemming  \\\n",
       "0                    so way plug us unless i go convert   \n",
       "1                                  good case excel valu   \n",
       "2                                          great jawbon   \n",
       "3       tie charger convers last 45 minut major problem   \n",
       "4                                         the mic great   \n",
       "...                                                 ...   \n",
       "2743                    i think food flavor textur lack   \n",
       "2744                             appetit instantli gone   \n",
       "2745                     overal i impress would go back   \n",
       "2746  the whole experi underwhelm i think go ninja s...   \n",
       "2747  then i wast enough life pour salt wound draw t...   \n",
       "\n",
       "                                       Text_spacy_lemma  \n",
       "0                                    way plug converter  \n",
       "1                             good case excellent value  \n",
       "2                                         great jawbone  \n",
       "3     tie charger conversation last minute major pro...  \n",
       "4                                             mic great  \n",
       "...                                                 ...  \n",
       "2743                     think food flavor texture lack  \n",
       "2744                              appetite instantly go  \n",
       "2745                                  overall impressed  \n",
       "2746    experience underwhelming think ninja sushi time  \n",
       "2747  waste life pour salt wound draw time take brin...  \n",
       "\n",
       "[2748 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Spacy\n",
    "nlp_spacy = spacy.load('en_core_web_sm')\n",
    "\n",
    "def spacy_lemma(text):\n",
    "    doc = nlp_spacy(text)\n",
    "    tokens = []\n",
    "    for word in doc:\n",
    "        if word.is_stop or word.is_punct or word.is_digit:\n",
    "            continue\n",
    "        else:\n",
    "            tokens.append(word.lemma_.lower())\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df_all['Text_spacy_lemma'] = df_all['Text'].apply(spacy_lemma)\n",
    "df_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3b8aff",
   "metadata": {},
   "source": [
    "# CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "83b87a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  document  first  is  one  second  the  third  this\n",
       "0    0         1      1   1    0       0    1      0     1\n",
       "1    0         2      0   1    0       1    1      0     1\n",
       "2    1         0      0   1    1       0    1      1     1\n",
       "3    0         1      1   1    0       0    1      0     1"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\n",
    "'This is the first document.',\n",
    "'This document is the second document.',\n",
    "'And this is the third one.',\n",
    "'Is this the first document?',\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "X = X.toarray()\n",
    "X_CountVectorizer = pd.DataFrame(X, columns=feature_names)\n",
    "X_CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4bb0966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yellowtail', 'yelp', 'yelper', 'yet', 'you', 'young', 'younger', 'your', 'youth', 'youtub', 'yucki', 'yukon', 'yum', 'yummi', 'yun', 'z500a', 'zero', 'zillion', 'zombi', 'zombiez']\n",
      "['young play', 'younger set', 'your brain', 'your server', 'your staff', 'youth energi', 'yukon gold', 'yum sauc', 'yum yum', 'yummi christma', 'yummi tri', 'yummi tummi', 'yun fat', 'z500a pretti', 'zero star', 'zero tast', 'zillion time', 'zombi movi', 'zombi student', 'zombiez part']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_stemming = vectorizer.fit_transform(df_all['Text_nltk_stemming'])\n",
    "print(vectorizer.get_feature_names()[-20:])\n",
    "X_stemming = X_stemming.toarray()\n",
    "\n",
    "# for two words\n",
    "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
    "X2_stemming = vectorizer2.fit_transform(df_all['Text_nltk_stemming'])\n",
    "print(vectorizer2.get_feature_names()[-20:])\n",
    "X2_stemming = X2_stemming.toarray()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed5a732c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4009</th>\n",
       "      <th>4010</th>\n",
       "      <th>4011</th>\n",
       "      <th>4012</th>\n",
       "      <th>4013</th>\n",
       "      <th>4014</th>\n",
       "      <th>4015</th>\n",
       "      <th>4016</th>\n",
       "      <th>4017</th>\n",
       "      <th>4018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2748 rows × 4019 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9     ...  4009  \\\n",
       "0        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "4        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "2743     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2744     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2745     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2746     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2747     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "      4010  4011  4012  4013  4014  4015  4016  4017  4018  \n",
       "0        0     0     0     0     0     0     0     0     0  \n",
       "1        0     0     0     0     0     0     0     0     0  \n",
       "2        0     0     0     0     0     0     0     0     0  \n",
       "3        0     0     0     0     0     0     0     0     0  \n",
       "4        0     0     0     0     0     0     0     0     0  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "2743     0     0     0     0     0     0     0     0     0  \n",
       "2744     0     0     0     0     0     0     0     0     0  \n",
       "2745     0     0     0     0     0     0     0     0     0  \n",
       "2746     0     0     0     0     0     0     0     0     0  \n",
       "2747     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[2748 rows x 4019 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3452e1",
   "metadata": {},
   "source": [
    "# Tfidf Transformer\n",
    "\n",
    "\n",
    "https://betterprogramming.pub/a-friendly-guide-to-nlp-tf-idf-with-python-example-5fcb26286a33\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "cf16f747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>0.580286</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538648</td>\n",
       "      <td>0.281089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267104</td>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267104</td>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.267104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>0.580286</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and  document     first        is       one    second       the  \\\n",
       "0  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
       "1  0.000000  0.687624  0.000000  0.281089  0.000000  0.538648  0.281089   \n",
       "2  0.511849  0.000000  0.000000  0.267104  0.511849  0.000000  0.267104   \n",
       "3  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
       "\n",
       "      third      this  \n",
       "0  0.000000  0.384085  \n",
       "1  0.000000  0.281089  \n",
       "2  0.511849  0.267104  \n",
       "3  0.000000  0.384085  "
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "'This is the first document.',\n",
    "'This document is the second document.',\n",
    "'And this is the third one.',\n",
    "'Is this the first document?',\n",
    "]\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "X = X.toarray()\n",
    "X_TfidfVectorizer = pd.DataFrame(X, columns=feature_names)\n",
    "X_TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "fdde99e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  document  first  is  one  second  the  third  this\n",
       "0    0         1      1   1    0       0    1      0     1\n",
       "1    0         2      0   1    0       1    1      0     1\n",
       "2    1         0      0   1    1       0    1      1     1\n",
       "3    0         1      1   1    0       0    1      0     1"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaea2813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yellowtail', 'yelp', 'yelper', 'yet', 'you', 'young', 'younger', 'your', 'youth', 'youtub', 'yucki', 'yukon', 'yum', 'yummi', 'yun', 'z500a', 'zero', 'zillion', 'zombi', 'zombiez']\n",
      "['young play', 'younger set', 'your brain', 'your server', 'your staff', 'youth energi', 'yukon gold', 'yum sauc', 'yum yum', 'yummi christma', 'yummi tri', 'yummi tummi', 'yun fat', 'z500a pretti', 'zero star', 'zero tast', 'zillion time', 'zombi movi', 'zombi student', 'zombiez part']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_stemming_tfidf = vectorizer.fit_transform(df_all['Text_nltk_stemming'])\n",
    "print(vectorizer.get_feature_names()[-20:])\n",
    "X_stemming_tfidf = X_stemming_tfidf.toarray()\n",
    "X_stemming_tfidf\n",
    "\n",
    "# for two words\n",
    "vectorizer2 = TfidfVectorizer(analyzer='word', ngram_range=(2, 2))\n",
    "X2_stemming_tfidf = vectorizer2.fit_transform(df_all['Text_nltk_stemming'])\n",
    "print(vectorizer2.get_feature_names()[-20:])\n",
    "X2_stemming_tfidf = X2_stemming_tfidf.toarray()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e548fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we have a transformed data to train the model\n",
    "X_stemming\n",
    "X2_stemming\n",
    "\n",
    "X_stemming_tfidf\n",
    "X2_stemming_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb31219",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b84a8978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d0c862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_all['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81602de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9596069868995634"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_stemming,y)\n",
    "clf.score(X_stemming,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
